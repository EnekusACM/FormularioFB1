{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EnekusACM/FormularioFB1/blob/master/Untitled7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7noSrBlwODmR",
        "outputId": "f4db0dc8-3e2d-426d-c849-4c302e5fc8a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Collecting h5py>=3.10.0 (from tensorflow)\n",
            "  Downloading h5py-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Collecting ml-dtypes~=0.3.1 (from tensorflow)\n",
            "  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.0)\n",
            "Collecting tensorboard<2.17,>=2.16 (from tensorflow)\n",
            "  Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras>=3.0.0 (from tensorflow)\n",
            "  Downloading keras-3.3.3-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n",
            "Collecting namex (from keras>=3.0.0->tensorflow)\n",
            "  Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
            "Collecting optree (from keras>=3.0.0->tensorflow)\n",
            "  Downloading optree-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n",
            "Installing collected packages: namex, optree, ml-dtypes, h5py, tensorboard, keras, tensorflow\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.2.0\n",
            "    Uninstalling ml-dtypes-0.2.0:\n",
            "      Successfully uninstalled ml-dtypes-0.2.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.9.0\n",
            "    Uninstalling h5py-3.9.0:\n",
            "      Successfully uninstalled h5py-3.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.2\n",
            "    Uninstalling tensorboard-2.15.2:\n",
            "      Successfully uninstalled tensorboard-2.15.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.15.0\n",
            "    Uninstalling tensorflow-2.15.0:\n",
            "      Successfully uninstalled tensorflow-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.16.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h5py-3.11.0 keras-3.3.3 ml-dtypes-0.3.2 namex-0.0.8 optree-0.11.0 tensorboard-2.16.2 tensorflow-2.16.1\n",
            "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.10/dist-packages (0.16.1)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-hub) (1.25.2)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow-hub) (3.20.3)\n",
            "Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-hub) (2.15.1)\n",
            "Collecting tensorflow<2.16,>=2.15 (from tf-keras>=2.14.1->tensorflow-hub)\n",
            "  Downloading tensorflow-2.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (0.3.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (24.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (1.64.0)\n",
            "Collecting tensorboard<2.16,>=2.15 (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub)\n",
            "  Downloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (2.15.0)\n",
            "Collecting keras<2.16,>=2.15.0 (from tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub)\n",
            "  Downloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras>=2.14.1->tensorflow-hub) (3.2.2)\n",
            "Installing collected packages: keras, tensorboard, tensorflow\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.3.3\n",
            "    Uninstalling keras-3.3.3:\n",
            "      Successfully uninstalled keras-3.3.3\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.16.2\n",
            "    Uninstalling tensorboard-2.16.2:\n",
            "      Successfully uninstalled tensorboard-2.16.2\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.16.1\n",
            "    Uninstalling tensorflow-2.16.1:\n",
            "      Successfully uninstalled tensorflow-2.16.1\n",
            "Successfully installed keras-2.15.0 tensorboard-2.15.2 tensorflow-2.15.1\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade tensorflow\n",
        "!pip install --upgrade tensorflow-hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pCcbz2AdiB-",
        "outputId": "cfc70fa3-58ea-489b-a56d-49d770ecb80a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Carpeta '1centimo' creada en '/content/dataset/1centimo'\n",
            "Carpeta '2centimos' creada en '/content/dataset/2centimos'\n",
            "Carpeta '5centimos1euro' creada en '/content/dataset/5centimos1euro'\n",
            "Carpeta '10centimos' creada en '/content/dataset/10centimos'\n",
            "Carpeta '20centimos' creada en '/content/dataset/20centimos'\n",
            "Carpeta '50centimos' creada en '/content/dataset/50centimos'\n",
            "Carpeta '1euro' creada en '/content/dataset/1euro'\n",
            "Carpeta '2euros' creada en '/content/dataset/2euros'\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Definir las carpetas a crear\n",
        "folders = {\n",
        "    '1centimo': 0,\n",
        "    '2centimos': 1,\n",
        "    '5centimos''1euro': 2,\n",
        "    '10centimos': 3,\n",
        "    '20centimos': 4,\n",
        "    '50centimos': 5,\n",
        "    '1euro': 6,\n",
        "    '2euros': 7\n",
        "}\n",
        "\n",
        "# Directorio base\n",
        "base_dir = '/content/dataset/'\n",
        "\n",
        "# Crear las carpetas\n",
        "for folder_name, _ in folders.items():\n",
        "    folder_path = os.path.join(base_dir, folder_name)\n",
        "    os.makedirs(folder_path, exist_ok=True)\n",
        "    print(f\"Carpeta '{folder_name}' creada en '{folder_path}'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuILe1wvdmXj",
        "outputId": "0ec09dd5-e349-4978-9b71-fdb1fca45af5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ".  ..  1c  1e  20c  2c\t2e  5c\tc10  c50\n",
            ".  ..  1c  1e  20c  2c\t2e  5c\tc10  c50\n"
          ]
        }
      ],
      "source": [
        "# Listar el contenido del directorio para ver la carpeta antes de borrarla\n",
        "!ls -a /content/dataset/\n",
        "\n",
        "# Borrar la carpeta .ipynb_checkpoints y su contenido\n",
        "import shutil\n",
        "carpeta_a_borrar = \"/content/dataset/.ipynb_checkpoints\"\n",
        "shutil.rmtree(carpeta_a_borrar)\n",
        "\n",
        "# Verificar que la carpeta ha sido borrada\n",
        "!ls -a /content/dataset/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NO_qRjJjo121"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Especificar la ruta del archivo zip\n",
        "zip_file_path = '/content/dataset.zip'\n",
        "\n",
        "# Crear una carpeta para descomprimir el contenido\n",
        "extract_path = '/content/data/'\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "# Descomprimir el archivo zip\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nep2tywjelzk"
      },
      "outputs": [],
      "source": [
        "# Ruta a las carpetas de imágenes\n",
        "dataset_path = '/content/dataset'\n",
        "image_size = (224, 224)\n",
        "batch_size = 32\n",
        "num_classes = 1  # Asumiendo que tienes 8 clases, una por cada moneda\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "C8ZeUWNVye6H",
        "outputId": "6fe67f89-9b31-4184-fb1f-2a9d6ed432a6"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'ImageDataGenerator' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-680f32d3ae7e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Crear un generador de datos con rescaling y división para validación\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdatagen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrescale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdataset_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/dataset'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Generador de entrenamiento\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m train_generator = datagen.flow_from_directory(\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ImageDataGenerator' is not defined"
          ]
        }
      ],
      "source": [
        "# Crear un generador de datos con rescaling y división para validación\n",
        "datagen = ImageDataGenerator(rescale=1.0/255.0, validation_split=0.2)\n",
        "dataset_path = '/content/dataset'\n",
        "# Generador de entrenamiento\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    dataset_path,  # Ruta a la carpeta base del dataset\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training'  # Usar subset de entrenamiento\n",
        ")\n",
        "print(\"Clases encontradas en entrenamiento:\", train_generator.class_indices)  # Imprimir las clases encontradas\n",
        "\n",
        "# Generador de validación\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    dataset_path,  # Ruta a la carpeta base del dataset\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'  # Usar subset de validación\n",
        ")\n",
        "print(\"Clases encontradas en validación:\", validation_generator.class_indices)  # Imprimir las clases encontradas\n",
        "\n",
        "# Descargar y cargar el modelo MobileNetV2\n",
        "model_url = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
        "feature_extractor_layer = hub.KerasLayer(model_url, input_shape=(224, 224, 3), trainable=False)\n",
        "\n",
        "# Construir el modelo\n",
        "model = tf.keras.Sequential([\n",
        "    feature_extractor_layer,\n",
        "    tf.keras.layers.Dense(1, activation='softmax')  # 8 clases\n",
        "])\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Entrenar el modelo\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=10,\n",
        "    validation_data=validation_generator\n",
        ")\n",
        "\n",
        "# Evaluar el modelo\n",
        "loss, accuracy = model.evaluate(validation_generator)\n",
        "print(f\"Precisión del modelo en el conjunto de validación: {accuracy:.2f}\")\n",
        "\n",
        "# Guardar el modelo\n",
        "model.save('coin_classifier_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H88RH9SoEu1j",
        "outputId": "9a1020fc-08f6-4e41-8245-a12195d95fce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 52ms/step\n",
            "La imagen se predice como: c10\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "def load_and_preprocess_image(img_path, target_size=(224, 224)):\n",
        "    img = image.load_img(img_path, target_size=target_size)\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Añadir una dimensión para el batch\n",
        "    img_array = img_array / 255.0  # Escalar la imagen\n",
        "    return img_array\n",
        "\n",
        "def predict_image(model, img_path, class_indices):\n",
        "    img_array = load_and_preprocess_image(img_path)\n",
        "    predictions = model.predict(img_array)\n",
        "    predicted_class_index = np.argmax(predictions, axis=1)[0]\n",
        "    class_labels = {v: k for k, v in class_indices.items()}\n",
        "    predicted_class_label = class_labels[predicted_class_index]\n",
        "    return predicted_class_label\n",
        "\n",
        "# Ejemplo de uso\n",
        "img_path = '/content/dataset/c10/imagen_variada_12.jpg'  # Reemplaza con la ruta a tu imagen\n",
        "predicted_class = predict_image(model, img_path, train_generator.class_indices)\n",
        "print(f\"La imagen se predice como: {predicted_class}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "ksnvgoR28w9h",
        "outputId": "bd085e01-7bf3-4006-a84f-9bb60702965f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4000 files belonging to 8 classes.\n",
            "Using 3200 files for training.\n",
            "Found 4000 files belonging to 8 classes.\n",
            "Using 800 files for validation.\n",
            "Epoch 1/20\n",
            "100/100 [==============================] - 167s 2s/step - loss: 1.4271 - accuracy: 0.4925 - val_loss: 1.0387 - val_accuracy: 0.6350\n",
            "Epoch 2/20\n",
            " 49/100 [=============>................] - ETA: 54s - loss: 0.8458 - accuracy: 0.7404"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-4c78e3081be7>\u001b[0m in \u001b[0;36m<cell line: 61>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m  \u001b[0;31m# Ajusta el número de épocas según tus necesidades\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "import os\n",
        "\n",
        "# Ruta a las carpetas de imágenes\n",
        "dataset_path = 'data/'\n",
        "image_size = (224, 224)\n",
        "batch_size = 32\n",
        "num_classes = 8  # Asegúrate de que tienes 3 clases\n",
        "\n",
        "# Preparar los datasets\n",
        "train_dataset = image_dataset_from_directory(\n",
        "    dataset_path,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=123,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "validation_dataset = image_dataset_from_directory(\n",
        "    dataset_path,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=123,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "# Normalizar los datos\n",
        "normalization_layer = layers.Rescaling(1./255)\n",
        "train_dataset = train_dataset.map(lambda x, y: (normalization_layer(x), y))\n",
        "validation_dataset = validation_dataset.map(lambda x, y: (normalization_layer(x), y))\n",
        "\n",
        "# Descargar y cargar el modelo MobileNetV2 desde TensorFlow Hub\n",
        "model_url = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
        "feature_extractor_layer = hub.KerasLayer(model_url, input_shape=(224, 224, 3), trainable=False)\n",
        "\n",
        "# Construir el modelo usando la API funcional\n",
        "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
        "x = feature_extractor_layer(inputs)\n",
        "outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Asegurarte de que las etiquetas estén en el formato correcto\n",
        "train_dataset = train_dataset.map(lambda x, y: (x, tf.one_hot(y, num_classes)))\n",
        "validation_dataset = validation_dataset.map(lambda x, y: (x, tf.one_hot(y, num_classes)))\n",
        "\n",
        "# Entrenar el modelo\n",
        "epochs = 20  # Ajusta el número de épocas según tus necesidades\n",
        "\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_dataset\n",
        ")\n",
        "\n",
        "# Evaluar el modelo\n",
        "loss, accuracy = model.evaluate(validation_dataset)\n",
        "print(f\"Precisión del modelo en el conjunto de validación: {accuracy:.2f}\")\n",
        "\n",
        "# Guardar el modelo entrenado\n",
        "model.save('coin_classifier_model10c.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Listar las etiquetas de las clases\n",
        "class_names = sorted(os.listdir(dataset_path))\n",
        "print(\"Etiquetas de las clases:\", class_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vh9Bg3qG3Cr",
        "outputId": "b49c4e61-9c11-46de-8c43-43b36a892ea6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Etiquetas de las clases: ['1c', '1e', '20c', '2c', '2e', '5c', 'c10', 'c50']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SusI67bIgxYB",
        "outputId": "8cb36913-2812-449a-b51a-80c2dfb2d96c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archivo dataset/1cc/imagen_variada_240.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_157.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_476.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_340.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_119.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_195.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_193.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_319.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_194.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_144.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_420.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_358.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_115.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_426.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_301.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_277.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_67.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_91.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_141.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_171.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_406.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_471.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_97.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_456.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_417.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_256.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_467.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_47.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_469.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_415.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_21.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_350.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_390.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_105.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_124.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_372.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_333.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_17.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_208.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_57.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_299.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_371.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_442.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_45.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_4.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_328.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_303.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_172.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_229.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_154.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_410.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_244.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_222.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_279.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_432.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_187.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_363.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_457.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_421.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_439.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_382.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_302.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_453.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_239.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_35.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_233.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_312.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_181.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_88.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_248.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_225.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_66.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_162.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_294.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_400.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_284.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_209.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_389.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_116.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_265.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_479.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_65.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_42.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_493.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_158.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_140.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_428.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_153.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_168.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_26.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_361.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_489.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_129.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_159.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_243.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_37.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_407.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_92.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_216.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_232.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_495.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_385.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_230.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_199.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_293.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_85.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_139.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_365.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_215.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_84.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_356.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_487.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_62.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_429.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_430.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_258.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_330.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_286.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_431.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_125.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_278.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_324.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_43.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_497.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_445.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_33.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_311.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_74.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_155.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_408.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_72.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_89.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_28.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_101.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_221.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_379.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_147.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_416.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_458.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_203.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_134.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_275.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_200.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_39.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_264.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_108.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_123.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_100.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_250.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_393.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_34.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_197.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_262.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_251.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_219.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_473.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_482.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_332.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_412.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_188.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_231.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_5.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_137.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_450.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_212.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_300.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_466.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_391.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_170.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_156.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_498.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_59.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_409.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_419.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_472.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_388.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_176.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_79.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_434.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_237.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_327.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_96.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_490.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_399.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_69.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_8.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_191.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_127.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_13.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_347.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_148.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_443.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_110.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_70.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_185.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_58.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_226.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_486.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_238.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_86.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_468.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_403.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_437.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_146.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_109.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_394.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_449.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_314.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_196.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_143.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_136.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_207.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_326.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_236.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_112.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_117.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_280.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_454.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_321.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_102.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_161.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_245.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_93.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_342.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_266.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_145.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_179.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_423.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_367.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_184.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_338.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_64.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_295.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_165.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_269.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_9.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_83.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_369.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_272.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_370.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_241.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_381.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_397.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_10.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_73.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_309.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_52.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_308.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_41.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_375.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_29.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_316.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_138.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_261.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_23.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_56.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_289.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_98.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_257.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_223.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_318.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_81.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_206.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_313.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_459.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_150.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_320.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_54.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_263.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_287.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_210.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_160.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_152.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_178.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_0.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_364.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_95.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_274.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_12.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_247.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_341.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_1.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_485.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_214.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_82.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_462.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_40.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_357.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_344.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_164.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_133.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_414.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_440.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_259.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_25.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_201.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_480.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_99.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_447.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_22.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_438.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_227.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_173.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_60.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_292.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_402.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_444.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_378.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_435.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_76.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_68.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_182.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_395.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_268.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_474.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_211.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_20.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_351.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_488.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_483.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_252.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_353.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_255.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_491.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_271.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_142.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_75.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_354.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_331.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_235.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_492.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_71.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_180.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_322.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_18.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_228.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_130.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_383.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_183.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_32.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_31.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_163.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_446.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_297.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_3.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_204.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_151.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_368.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_404.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_190.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_113.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_260.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_396.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_128.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_334.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_283.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_323.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_291.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_298.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_411.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_460.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_348.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_336.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_325.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_452.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_78.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_213.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_373.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_352.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_120.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_296.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_149.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_189.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_107.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_494.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_276.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_11.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_310.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_174.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_175.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_290.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_30.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_380.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_461.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_90.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_392.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_253.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_304.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_94.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_305.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_24.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_448.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_44.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_425.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_359.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_441.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_374.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_55.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_398.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_246.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_339.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_345.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_103.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_463.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_217.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_422.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_132.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_121.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_7.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_496.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_386.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_177.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_122.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_499.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_387.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_61.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_242.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_362.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_2.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_46.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_360.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_167.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_50.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_317.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_384.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_484.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_270.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_436.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_36.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_49.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_14.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_192.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_234.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_464.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_376.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_418.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_465.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_413.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_478.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_63.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_220.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_106.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_405.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_224.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_118.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_198.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_51.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_366.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_477.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_166.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_48.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_343.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_254.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_475.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_169.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_53.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_335.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_285.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_205.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_111.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_218.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_427.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_288.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_451.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_424.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_80.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_249.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_337.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_186.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_19.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_27.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_433.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_77.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_481.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_329.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_346.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_104.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_349.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_16.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_282.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_401.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_38.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_135.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_307.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_15.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_455.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_131.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_6.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_315.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_377.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_126.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_355.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_87.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_306.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_202.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_470.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_267.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_273.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_281.jpg eliminado.\n",
            "Archivo dataset/1cc/imagen_variada_114.jpg eliminado.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "# Ruta a la carpeta de 10 céntimos\n",
        "folder_path = 'dataset/1cc/'\n",
        "\n",
        "# Utilizar glob para obtener todos los archivos en la carpeta\n",
        "files = glob.glob(os.path.join(folder_path, '*'))\n",
        "\n",
        "# Iterar y eliminar cada archivo\n",
        "for file in files:\n",
        "    try:\n",
        "        os.remove(file)\n",
        "        print(f'Archivo {file} eliminado.')\n",
        "    except Exception as e:\n",
        "        print(f'Error al eliminar el archivo {file}: {e}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csokzuALsCSE",
        "outputId": "37705e69-faee-4442-969b-2f68151d9b8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 4000 images belonging to 8 classes.\n",
            "Found 0 images belonging to 8 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "train_dataset = datagen.flow_from_directory(\n",
        "    dataset_path,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    seed=123\n",
        ")\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "validation_dataset = validation_datagen.flow_from_directory(\n",
        "    dataset_path,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    seed=123\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZG8HHV6st2Op"
      },
      "source": [
        "--------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FdedkYNEtveB",
        "outputId": "4eb5106b-5a77-4958-8226-e22a19b508ae"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-6c3f86022598>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mearly_stopping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36m_assert_compile_was_called\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3981\u001b[0m         \u001b[0;31m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3982\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3983\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   3984\u001b[0m                 \u001b[0;34m\"You must compile your model before \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3985\u001b[0m                 \u001b[0;34m\"training/testing. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.0001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
        "x = feature_extractor_layer(inputs)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aiKEO4pYsGWi"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Función para cargar y preprocesar una imagen\n",
        "def load_and_preprocess_image(img_path, target_size=(224, 224)):\n",
        "    img = image.load_img(img_path, target_size=target_size)\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Añadir una dimensión para el batch\n",
        "    img_array = img_array / 255.0  # Escalar la imagen\n",
        "    return img_array\n",
        "\n",
        "# Función para predecir la clase de una imagen\n",
        "def predict_image(model, img_path, class_indices):\n",
        "    img_array = load_and_preprocess_image(img_path)\n",
        "    predictions = model.predict(img_array)\n",
        "    predicted_class_index = np.argmax(predictions, axis=1)[0]\n",
        "    class_labels = {v: k for k, v in class_indices.items()}\n",
        "    predicted_class_label = class_labels[predicted_class_index]\n",
        "    return predicted_class_label\n",
        "\n",
        "# Ejemplo de uso\n",
        "img_path = 'ruta/a/tu/imagen.jpg'  # Reemplaza con la ruta a tu imagen\n",
        "predicted_class = predict_image(model, img_path, train_generator.class_indices)\n",
        "print(f\"La imagen se predice como: {predicted_class}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMC635RHw+ibeo0zGPfeQVP",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}